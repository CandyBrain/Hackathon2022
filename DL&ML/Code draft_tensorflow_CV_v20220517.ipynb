{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f25f348",
   "metadata": {},
   "source": [
    "# 1. 기본설정\n",
    "## (1) 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "867e14e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### 1. 기본 설정 ##########################\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "######################### 2. 데이터 전처리 ########################\n",
    "### (1) 데이터 증강 \n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageFilter\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "### (3) 데이터 분리 \n",
    "\n",
    "\n",
    "#################### 3. 모델 학습 및 결과 검증 ####################\n",
    "### (1) 모델 설계 및 대표 벡터 추출 \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D, MaxPool2D, concatenate\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "### (2) 분류 예측 \n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e367db",
   "metadata": {},
   "source": [
    "## (2) 파라미터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e43fc1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### 1. 기본 설정 ##########################\n",
    "\n",
    "\n",
    "######################### 2. 데이터 전처리 ########################\n",
    "### (1) 데이터 증강 \n",
    "\n",
    "upsize_factor = 0  # 0: 1배, 1: 4배, 2:16배... 1올라갈 때마다 4배씩 증가. 아직은 1만 유효.\n",
    "\n",
    "blur_filter = True\n",
    "contour_filter = False\n",
    "edge_enhance_filter = False\n",
    "\n",
    "filter_num = 0  # 위에서 설정한 필터의 사용 개수(True의 개수)에 따라 자동 변경. 건드리지 말 것.\n",
    "\n",
    "if blur_filter == True:\n",
    "    filter_num += 1\n",
    "if contour_filter == True:\n",
    "    filter_num += 1\n",
    "if edge_enhance_filter == True:\n",
    "    filter_num += 1\n",
    "    \n",
    "### (3) 데이터 분리 \n",
    "\n",
    "# tts_test_size = 0.2\n",
    "# test_size = 0.15   # 1미만. val_size와의 합이 0.5를 넘지 않게.\n",
    "# val_size = 0.15   # 1미만. test_size와의 합이 0.5를 넘지 않게.\n",
    "\n",
    "train_test_split_randomstate = 5\n",
    "\n",
    "\n",
    "#################### 3. 모델 학습 및 결과 검증 ####################\n",
    "### (1) 모델 설계 및 대표 벡터 추출 \n",
    "raw_image_size = 8\n",
    "upsized_image_size = raw_image_size * (4 ** upsize_factor)\n",
    "class_num = 6    # 대상 개수\n",
    "\n",
    "is_global_feature = False  # Global feature 사용 여부 지정.\n",
    "classes_num = 6\n",
    "epoch_num = 20\n",
    "\n",
    "### (2) 분류 예측 \n",
    "classifier_random_state = 32\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0edca36",
   "metadata": {},
   "source": [
    "## (3) 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25e5a790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = 'C:/Users/user/Documents/GitHub/Hackathon2022/Dataset/'  # Github 경로\n",
    "data_dir = 'C:/Users/user/Google 드라이브/AIFFEL/+Final project/data/20220519/'  # Google drive 경로\n",
    "\n",
    "# data1 부분 데이터 로드\n",
    "data_path1_1 = os.path.join(data_dir, '8x8Test_20220519_11_Cham_HardWood_NoCushion_Po1.csv')\n",
    "data1_1 = pd.read_csv(data_path1_1)\n",
    "\n",
    "data_path1_2 = os.path.join(data_dir, '8x8Test_20220519_11_Cham_HardWood_NoCushion_Po2.csv')\n",
    "data1_2 = pd.read_csv(data_path1_2)\n",
    "\n",
    "data_path1_3 = os.path.join(data_dir, '8x8Test_20220519_11_Cham_HardWood_NoCushion_Po3.csv')\n",
    "data1_3 = pd.read_csv(data_path1_3)\n",
    "\n",
    "data_path1_4 = os.path.join(data_dir, '8x8Test_20220519_11_Cham_HardWood_NoCushion_Po4.csv')\n",
    "data1_4 = pd.read_csv(data_path1_4)\n",
    "\n",
    "data_path1_5 = os.path.join(data_dir, '8x8Test_20220519_11_Cham_HardWood_NoCushion_Po5.csv')\n",
    "data1_5 = pd.read_csv(data_path1_5)\n",
    "\n",
    "data_path1_6 = os.path.join(data_dir, '8x8Test_20220519_11_Cham_HardWood_NoCushion_Po6.csv')\n",
    "data1_6 = pd.read_csv(data_path1_6)\n",
    "\n",
    "data_path1_7 = os.path.join(data_dir, '8x8Test_20220519_11_Cham_HardWood_NoCushion_Po7.csv')\n",
    "data1_7 = pd.read_csv(data_path1_7)\n",
    "\n",
    "data_path1_8 = os.path.join(data_dir, '8x8Test_20220519_11_Cham_HardWood_NoCushion_Po8.csv')\n",
    "data1_8 = pd.read_csv(data_path1_8)\n",
    "\n",
    "data_path1_9 = os.path.join(data_dir, '8x8Test_20220519_11_Cham_HardWood_NoCushion_Po9.csv')\n",
    "data1_9 = pd.read_csv(data_path1_9)\n",
    "\n",
    "\n",
    "# data2 부분 데이터 로드\n",
    "data_path2_1 = os.path.join(data_dir, '8x8Test_20220519_12_Moon_HardWood_NoCushion_Po1.csv')\n",
    "data2_1 = pd.read_csv(data_path1_1)\n",
    "\n",
    "data_path2_2 = os.path.join(data_dir, '8x8Test_20220519_12_Moon_HardWood_NoCushion_Po2.csv')\n",
    "data2_2 = pd.read_csv(data_path1_2)\n",
    "\n",
    "data_path2_3 = os.path.join(data_dir, '8x8Test_20220519_12_Moon_HardWood_NoCushion_Po3.csv')\n",
    "data2_3 = pd.read_csv(data_path1_3)\n",
    "\n",
    "data_path2_4 = os.path.join(data_dir, '8x8Test_20220519_12_Moon_HardWood_NoCushion_Po4.csv')\n",
    "data2_4 = pd.read_csv(data_path1_4)\n",
    "\n",
    "data_path2_5 = os.path.join(data_dir, '8x8Test_20220519_12_Moon_HardWood_NoCushion_Po5.csv')\n",
    "data2_5 = pd.read_csv(data_path1_5)\n",
    "\n",
    "data_path2_6 = os.path.join(data_dir, '8x8Test_20220519_12_Moon_HardWood_NoCushion_Po6.csv')\n",
    "data2_6 = pd.read_csv(data_path1_6)\n",
    "\n",
    "data_path2_7 = os.path.join(data_dir, '8x8Test_20220519_12_Moon_HardWood_NoCushion_Po7.csv')\n",
    "data2_7 = pd.read_csv(data_path1_7)\n",
    "\n",
    "data_path2_8 = os.path.join(data_dir, '8x8Test_20220519_12_Moon_HardWood_NoCushion_Po8.csv')\n",
    "data2_8 = pd.read_csv(data_path1_8)\n",
    "\n",
    "data_path2_9 = os.path.join(data_dir, '8x8Test_20220519_12_Moon_HardWood_NoCushion_Po9.csv')\n",
    "data2_9 = pd.read_csv(data_path1_9)\n",
    "\n",
    "\n",
    "# data3 부분 데이터 로드\n",
    "data_path3_1 = os.path.join(data_dir, '8x8Test_20220519_13_Shin_HardWood_NoCushion_Po1.csv')\n",
    "data3_1 = pd.read_csv(data_path3_1)\n",
    "\n",
    "data_path3_2 = os.path.join(data_dir, '8x8Test_20220519_13_Shin_HardWood_NoCushion_Po2.csv')\n",
    "data3_2 = pd.read_csv(data_path3_2)\n",
    "\n",
    "data_path3_3 = os.path.join(data_dir, '8x8Test_20220519_13_Shin_HardWood_NoCushion_Po3.csv')\n",
    "data3_3 = pd.read_csv(data_path3_3)\n",
    "\n",
    "data_path3_4 = os.path.join(data_dir, '8x8Test_20220519_13_Shin_HardWood_NoCushion_Po4.csv')\n",
    "data3_4 = pd.read_csv(data_path3_4)\n",
    "\n",
    "data_path3_5 = os.path.join(data_dir, '8x8Test_20220519_13_Shin_HardWood_NoCushion_Po5.csv')\n",
    "data3_5 = pd.read_csv(data_path3_5)\n",
    "\n",
    "data_path3_6 = os.path.join(data_dir, '8x8Test_20220519_13_Shin_HardWood_NoCushion_Po6.csv')\n",
    "data3_6 = pd.read_csv(data_path3_6)\n",
    "\n",
    "data_path3_7 = os.path.join(data_dir, '8x8Test_20220519_13_Shin_HardWood_NoCushion_Po7.csv')\n",
    "data3_7 = pd.read_csv(data_path3_7)\n",
    "\n",
    "data_path3_8 = os.path.join(data_dir, '8x8Test_20220519_13_Shin_HardWood_NoCushion_Po8.csv')\n",
    "data3_8 = pd.read_csv(data_path3_8)\n",
    "\n",
    "data_path3_9 = os.path.join(data_dir, '8x8Test_20220519_13_Shin_HardWood_NoCushion_Po9.csv')\n",
    "data3_9 = pd.read_csv(data_path3_9)\n",
    "\n",
    "\n",
    "# data4 부분 데이터 로드\n",
    "data_path4_1 = os.path.join(data_dir, '8x8Test_20220519_14_Lee_HardWood_NoCushion_Po1.csv')\n",
    "data4_1 = pd.read_csv(data_path4_1)\n",
    "\n",
    "data_path4_2 = os.path.join(data_dir, '8x8Test_20220519_14_Lee_HardWood_NoCushion_Po2.csv')\n",
    "data4_2 = pd.read_csv(data_path4_2)\n",
    "\n",
    "data_path4_3 = os.path.join(data_dir, '8x8Test_20220519_14_Lee_HardWood_NoCushion_Po3.csv')\n",
    "data4_3 = pd.read_csv(data_path4_3)\n",
    "\n",
    "data_path4_4 = os.path.join(data_dir, '8x8Test_20220519_14_Lee_HardWood_NoCushion_Po4.csv')\n",
    "data4_4 = pd.read_csv(data_path4_4)\n",
    "\n",
    "data_path4_5 = os.path.join(data_dir, '8x8Test_20220519_14_Lee_HardWood_NoCushion_Po5.csv')\n",
    "data4_5 = pd.read_csv(data_path4_5)\n",
    "\n",
    "data_path4_6 = os.path.join(data_dir, '8x8Test_20220519_14_Lee_HardWood_NoCushion_Po6.csv')\n",
    "data4_6 = pd.read_csv(data_path4_6)\n",
    "\n",
    "data_path4_7 = os.path.join(data_dir, '8x8Test_20220519_14_Lee_HardWood_NoCushion_Po7.csv')\n",
    "data4_7 = pd.read_csv(data_path4_7)\n",
    "\n",
    "data_path4_8 = os.path.join(data_dir, '8x8Test_20220519_14_Lee_HardWood_NoCushion_Po8.csv')\n",
    "data4_8 = pd.read_csv(data_path4_8)\n",
    "\n",
    "data_path4_9 = os.path.join(data_dir, '8x8Test_20220519_14_Lee_HardWood_NoCushion_Po9.csv')\n",
    "data4_9 = pd.read_csv(data_path4_9)\n",
    "\n",
    "\n",
    "# data5 부분 데이터 로드\n",
    "data_path5_1 = os.path.join(data_dir, '8x8Test_20220519_15_LeeJea_HardWood_NoCushion_Po1.csv')\n",
    "data5_1 = pd.read_csv(data_path5_1)\n",
    "\n",
    "data_path5_2 = os.path.join(data_dir, '8x8Test_20220519_15_LeeJea_HardWood_NoCushion_Po2.csv')\n",
    "data5_2 = pd.read_csv(data_path5_2)\n",
    "\n",
    "data_path5_3 = os.path.join(data_dir, '8x8Test_20220519_15_LeeJea_HardWood_NoCushion_Po3.csv')\n",
    "data5_3 = pd.read_csv(data_path5_3)\n",
    "\n",
    "data_path5_4 = os.path.join(data_dir, '8x8Test_20220519_15_LeeJea_HardWood_NoCushion_Po4.csv')\n",
    "data5_4 = pd.read_csv(data_path5_4)\n",
    "\n",
    "data_path5_5 = os.path.join(data_dir, '8x8Test_20220519_15_LeeJea_HardWood_NoCushion_Po5.csv')\n",
    "data5_5 = pd.read_csv(data_path5_5)\n",
    "\n",
    "data_path5_6 = os.path.join(data_dir, '8x8Test_20220519_15_LeeJea_HardWood_NoCushion_Po6.csv')\n",
    "data5_6 = pd.read_csv(data_path5_6)\n",
    "\n",
    "data_path5_7 = os.path.join(data_dir, '8x8Test_20220519_15_LeeJea_HardWood_NoCushion_Po7.csv')\n",
    "data5_7 = pd.read_csv(data_path5_7)\n",
    "\n",
    "data_path5_8 = os.path.join(data_dir, '8x8Test_20220519_15_LeeJea_HardWood_NoCushion_Po8.csv')\n",
    "data5_8 = pd.read_csv(data_path5_8)\n",
    "\n",
    "data_path5_9 = os.path.join(data_dir, '8x8Test_20220519_15_LeeJea_HardWood_NoCushion_Po9.csv')\n",
    "data5_9 = pd.read_csv(data_path5_9)\n",
    "\n",
    "\n",
    "# data6 부분 데이터 로드\n",
    "data_path6_1 = os.path.join(data_dir, '8x8Test_20220519_16_You_HardWood_NoCushion_Po1.csv')\n",
    "data6_1 = pd.read_csv(data_path6_1)\n",
    "\n",
    "data_path6_2 = os.path.join(data_dir, '8x8Test_20220519_16_You_HardWood_NoCushion_Po2.csv')\n",
    "data6_2 = pd.read_csv(data_path6_2)\n",
    "\n",
    "data_path6_3 = os.path.join(data_dir, '8x8Test_20220519_16_You_HardWood_NoCushion_Po3.csv')\n",
    "data6_3 = pd.read_csv(data_path6_3)\n",
    "\n",
    "data_path6_4 = os.path.join(data_dir, '8x8Test_20220519_16_You_HardWood_NoCushion_Po4.csv')\n",
    "data6_4 = pd.read_csv(data_path6_4)\n",
    "\n",
    "data_path6_5 = os.path.join(data_dir, '8x8Test_20220519_16_You_HardWood_NoCushion_Po5.csv')\n",
    "data6_5 = pd.read_csv(data_path6_5)\n",
    "\n",
    "data_path6_6 = os.path.join(data_dir, '8x8Test_20220519_16_You_HardWood_NoCushion_Po6.csv')\n",
    "data6_6 = pd.read_csv(data_path6_6)\n",
    "\n",
    "data_path6_7 = os.path.join(data_dir, '8x8Test_20220519_16_You_HardWood_NoCushion_Po7.csv')\n",
    "data6_7 = pd.read_csv(data_path6_7)\n",
    "\n",
    "data_path6_8 = os.path.join(data_dir, '8x8Test_20220519_16_You_HardWood_NoCushion_Po8.csv')\n",
    "data6_8 = pd.read_csv(data_path6_8)\n",
    "\n",
    "data_path6_9 = os.path.join(data_dir, '8x8Test_20220519_16_You_HardWood_NoCushion_Po9.csv')\n",
    "data6_9 = pd.read_csv(data_path6_9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea226171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data1 = pd.concat([data1_1.iloc[:10], data1_2.iloc[:10], data1_3.iloc[:10], data1_4.iloc[:10],data1_5.iloc[:10],\n",
    "#                  data1_6.iloc[:10], data1_7.iloc[:10], data1_8.iloc[:10], data1_9.iloc[:10]])  # 10개 행씩 추려 합침.\n",
    "# data1['Label'] = 1 # Label 부여\n",
    "\n",
    "# data2 = pd.concat([data2_1.iloc[:10], data2_2.iloc[:10], data2_3.iloc[:10], data2_4.iloc[:10],data2_5.iloc[:10],\n",
    "#                  data2_6.iloc[:10], data2_7.iloc[:10], data2_8.iloc[:10], data2_9.iloc[:10]])  # 10개 행씩 추려 합침.\n",
    "# data2['Label'] = 2 # Label 부여\n",
    "\n",
    "# data3 = pd.concat([data3_1.iloc[:10], data3_2.iloc[:10], data3_3.iloc[:10], data3_4.iloc[:10],data3_5.iloc[:10],\n",
    "#                  data3_6.iloc[:10], data3_7.iloc[:10], data3_8.iloc[:10], data3_9.iloc[:10]])  # 10개 행씩 추려 합침.\n",
    "# data3['Label'] = 3 # Label 부여\n",
    "\n",
    "# data4 = pd.concat([data4_1.iloc[:10], data4_2.iloc[:10], data4_3.iloc[:10], data4_4.iloc[:10],data4_5.iloc[:10],\n",
    "#                  data4_6.iloc[:10], data4_7.iloc[:10], data4_8.iloc[:10], data4_9.iloc[:10]])  # 10개 행씩 추려 합침.\n",
    "# data4['Label'] = 4 # Label 부여\n",
    "\n",
    "# data5 = pd.concat([data5_1.iloc[:10], data5_2.iloc[:10], data5_3.iloc[:10], data5_4.iloc[:10],data5_5.iloc[:10],\n",
    "#                  data5_6.iloc[:10], data5_7.iloc[:10], data5_8.iloc[:10], data5_9.iloc[:10]])  # 10개 행씩 추려 합침.\n",
    "# data5['Label'] = 5 # Label 부여\n",
    "\n",
    "# data6 = pd.concat([data6_1.iloc[:10], data6_2.iloc[:10], data6_3.iloc[:10], data6_4.iloc[:10],data6_5.iloc[:10],\n",
    "#                  data6_6.iloc[:10], data6_7.iloc[:10], data6_8.iloc[:10], data6_9.iloc[:10]])  # 10개 행씩 추려 합침.\n",
    "# data6['Label'] = 6 # Label 부여\n",
    "\n",
    "\n",
    "\n",
    "data1 = pd.concat([data1_1.iloc[:50], data1_2.iloc[:50], data1_3.iloc[:50], data1_4.iloc[:50],data1_5.iloc[:50],\n",
    "                 data1_6.iloc[:50], data1_7.iloc[:50], data1_8.iloc[:50], data1_9.iloc[:50]])  # 50개 행씩 추려 합침.\n",
    "data1['Label'] = 1 # Label 부여\n",
    "\n",
    "data2 = pd.concat([data2_1.iloc[:50], data2_2.iloc[:50], data2_3.iloc[:50], data2_4.iloc[:50],data2_5.iloc[:50],\n",
    "                 data2_6.iloc[:50], data2_7.iloc[:50], data2_8.iloc[:50], data2_9.iloc[:50]])  # 50개 행씩 추려 합침.\n",
    "data2['Label'] = 2 # Label 부여\n",
    "\n",
    "data3 = pd.concat([data3_1.iloc[:50], data3_2.iloc[:50], data3_3.iloc[:50], data3_4.iloc[:50],data3_5.iloc[:50],\n",
    "                 data3_6.iloc[:50], data3_7.iloc[:50], data3_8.iloc[:50], data3_9.iloc[:50]])  # 50개 행씩 추려 합침.\n",
    "data3['Label'] = 3 # Label 부여\n",
    "\n",
    "data4 = pd.concat([data4_1.iloc[:50], data4_2.iloc[:50], data4_3.iloc[:50], data4_4.iloc[:50],data4_5.iloc[:50],\n",
    "                 data4_6.iloc[:50], data4_7.iloc[:50], data4_8.iloc[:50], data4_9.iloc[:50]])  # 50개 행씩 추려 합침.\n",
    "data4['Label'] = 4 # Label 부여\n",
    "\n",
    "data5 = pd.concat([data5_1.iloc[:50], data5_2.iloc[:50], data5_3.iloc[:50], data5_4.iloc[:50],data5_5.iloc[:50],\n",
    "                 data5_6.iloc[:50], data5_7.iloc[:50], data5_8.iloc[:50], data5_9.iloc[:50]])  # 50개 행씩 추려 합침.\n",
    "data5['Label'] = 5 # Label 부여\n",
    "\n",
    "data6 = pd.concat([data6_1.iloc[:50], data6_2.iloc[:50], data6_3.iloc[:50], data6_4.iloc[:50],data6_5.iloc[:50],\n",
    "                 data6_6.iloc[:50], data6_7.iloc[:50], data6_8.iloc[:50], data6_9.iloc[:50]])  # 50개 행씩 추려 합침.\n",
    "data6['Label'] = 6 # Label 부여\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efa4a416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(450, 65)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FSR1</th>\n",
       "      <th>FSR2</th>\n",
       "      <th>FSR3</th>\n",
       "      <th>FSR4</th>\n",
       "      <th>FSR5</th>\n",
       "      <th>FSR6</th>\n",
       "      <th>FSR7</th>\n",
       "      <th>FSR8</th>\n",
       "      <th>FSR9</th>\n",
       "      <th>FSR10</th>\n",
       "      <th>...</th>\n",
       "      <th>FSR56</th>\n",
       "      <th>FSR57</th>\n",
       "      <th>FSR58</th>\n",
       "      <th>FSR59</th>\n",
       "      <th>FSR60</th>\n",
       "      <th>FSR61</th>\n",
       "      <th>FSR62</th>\n",
       "      <th>FSR63</th>\n",
       "      <th>FSR64</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   FSR1  FSR2  FSR3  FSR4  FSR5  FSR6  FSR7  FSR8  FSR9  FSR10  ...  FSR56  \\\n",
       "0     0     0     0     0     0     0     0     0     0     23  ...      0   \n",
       "1     0     0     0     0     0     0     0     0     0     25  ...      0   \n",
       "2     0     0     0     0     0     0     0     0     0     24  ...      0   \n",
       "3     0     0     0     0     0     0     0     0     0     26  ...      0   \n",
       "4     0     0     0     0     0     0     0     0     0     28  ...      0   \n",
       "\n",
       "   FSR57  FSR58  FSR59  FSR60  FSR61  FSR62  FSR63  FSR64  Label  \n",
       "0      0      0      0      0      0      0      0      0      6  \n",
       "1      0      0      0      0      0      0      0      0      6  \n",
       "2      0      0      0      0      0      0      0      0      6  \n",
       "3      0      0      0      0      0      0      0      0      6  \n",
       "4      0      0      0      0      0      0      0      0      6  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(data6))\n",
    "print(data6.shape)\n",
    "data6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9f00c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = pd.concat([data1[:80], data2[:80], data3[:80], data4[:80], data5[:80], data6[:80]])  # 1~8번 자세\n",
    "# test_data = pd.concat([data1[80:], data2[80:], data3[80:], data4[80:], data5[80:], data6[80:]])  # 9번 자세\n",
    "\n",
    "train_data = pd.concat([data1[:400], data2[:400], data3[:400], data4[:400], data5[:400], data6[:400]])  # 1~8번 자세\n",
    "test_data = pd.concat([data1[400:], data2[400:], data3[400:], data4[400:], data5[400:], data6[400:]])  # 9번 자세\n",
    "# feature_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b6007dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data.drop(['Unnamed: 0'], axis = 1)\n",
    "# data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6066ffc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data.sample(frac = 1)\n",
    "# # data = data.sample(frac = 1).reset_index(drop = True)\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64169dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 64)\n",
      "(2400,)\n",
      "(300, 64)\n",
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "feature_train = train_data.iloc[:,:-1]\n",
    "label_train = train_data.iloc[:, -1]\n",
    "feature_test = test_data.iloc[:,:-1]\n",
    "label_test = test_data.iloc[:, -1]\n",
    "print(feature_train.shape)\n",
    "print(label_train.shape)\n",
    "print(feature_test.shape)\n",
    "print(label_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "869e7e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어레이 변환된 훈련 feature의 shape: (2400, 8, 8)\n",
      "어레이 변환된 테스트 feature의 shape: (300, 8, 8)\n"
     ]
    }
   ],
   "source": [
    "temp_array_feature_train = feature_train.to_numpy()\n",
    "\n",
    "list_feature_train = []\n",
    "for i in range(len(temp_array_feature_train)):\n",
    "    reshaped_array = temp_array_feature_train[i].reshape(raw_image_size,raw_image_size)\n",
    "    list_feature_train.append(reshaped_array)\n",
    "    \n",
    "array_feature_train = np.array(list_feature_train)\n",
    "array_feature_train = array_feature_train.astype('uint8')\n",
    "\n",
    "print(\"어레이 변환된 훈련 feature의 shape:\", array_feature_train.shape)\n",
    "\n",
    "temp_array_feature_test = feature_test.to_numpy()\n",
    "\n",
    "list_feature_test = []\n",
    "for i in range(len(temp_array_feature_test)):\n",
    "    reshaped_array = temp_array_feature_test[i].reshape(raw_image_size,raw_image_size)\n",
    "    list_feature_test.append(reshaped_array)\n",
    "    \n",
    "array_feature_test = np.array(list_feature_test)\n",
    "array_feature_test = array_feature_test.astype('uint8')\n",
    "\n",
    "print(\"어레이 변환된 테스트 feature의 shape:\", array_feature_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed5a97cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_feature_train[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e17734cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 이미지화\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('데이터 이미지화')\n",
    "plt.imshow(array_feature_train[1] , cmap='gray')\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a347e6d2",
   "metadata": {},
   "source": [
    "# 2. 데이터 전처리\n",
    "## (1) 데이터 증강"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b24f84f",
   "metadata": {},
   "source": [
    "### 이미지 리사이즈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bdf9c005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사이즈 변경 전 이미지 크기: (8, 8)\n",
      "사이즈 변경 후 이미지 크기: (8, 8)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"사이즈 변경 전 이미지 크기: {}\".format(array_feature_train[1].shape))\n",
    "def image_upsize(array_feature, upsize_factor):\n",
    "    \n",
    "    SAVED_MODEL_PATH = \"https://tfhub.dev/captain-pool/esrgan-tf2/1\" \n",
    "    super_resolution_model = hub.load(SAVED_MODEL_PATH) # 3채널에서만 작동.\n",
    "    tf_array_feature = tf.convert_to_tensor(array_feature)\n",
    "    tf_array_feature = tf.cast(tf_array_feature, tf.float32) # uint8 -> float32\n",
    "    upsized_array_feature = []\n",
    "    for i, array in enumerate(tf_array_feature):\n",
    "        \n",
    "        # model은 3채널용이므로, 이미지를 1채널 -> 3채널로 확장\n",
    "        temp_array = copy.deepcopy(array)\n",
    "        temp_array = tf.expand_dims(temp_array, 2)\n",
    "        temp_array = tf.expand_dims(temp_array, 0)\n",
    "        temp_array_2 = copy.deepcopy(temp_array)\n",
    "        temp_array_3 = copy.deepcopy(temp_array)\n",
    "        temp_array = np.concatenate((temp_array, temp_array_2), axis = 3)\n",
    "        temp_array = np.concatenate((temp_array, temp_array_3), axis = 3)\n",
    "    \n",
    "        # 업사이즈 적용\n",
    "        if upsize_factor > 0:\n",
    "            for i in range(upsize_factor):\n",
    "                temp_array = super_resolution_model(temp_array) \n",
    "        \n",
    "        # 3채널 -> 1채널로 복구\n",
    "        upsized_temp_array = tf.squeeze(temp_array)\n",
    "        grayscale_upsized_temp_array = (upsized_temp_array[:,:,0] + \n",
    "                                        upsized_temp_array[:,:,1] + upsized_temp_array[:,:,2])/3\n",
    "        upsized_array_feature.append(grayscale_upsized_temp_array)\n",
    "#         if i == 3:\n",
    "#             break\n",
    "    return np.array(upsized_array_feature)\n",
    "# print(\"upsize 전:\",array_feature.shape)\n",
    "array_feature_train = image_upsize(array_feature_train, upsize_factor)\n",
    "array_feature_test = image_upsize(array_feature_test, upsize_factor)\n",
    "# print(\"upsize 후:\",array_feature.shape)\n",
    "print(\"사이즈 변경 후 이미지 크기: {}\".format(array_feature_train[1].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27643a1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(array_feature_train[1] , cmap='gray')\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5508608f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ffec5478e0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_image = Image.fromarray(array_feature_train[1])\n",
    "plt.imshow(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cff6df6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_image_BLUR = test_image.filter(ImageFilter.BLUR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0620d0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# array_feature에 filter augmented data를 concatenate.\n",
    "def filter_concat(array_feature, blur_filter = False, contour_filter = False, \n",
    "                  edge_enhance_filter = False):\n",
    "    \n",
    "    filteradded_array_feature = []\n",
    "    \n",
    "    for i, j in enumerate(array_feature):\n",
    "        image = Image.fromarray(array_feature[i])\n",
    "        stack_array = np.expand_dims(array_feature[i], axis = 2)\n",
    "        \n",
    "        if blur_filter:\n",
    "            image_BLUR = image.filter(ImageFilter.BLUR)\n",
    "            blur_array_feature = np.array(image_BLUR)\n",
    "            blur_stack_array = np.expand_dims(blur_array_feature, axis = 2)\n",
    "            stack_array = np.concatenate((stack_array, blur_stack_array), axis = 2)\n",
    "            \n",
    "        if contour_filter:\n",
    "            image_CONTOUR = image.filter(ImageFilter.CONTOUR)\n",
    "            contour_array_feature = np.array(image_CONTOUR)\n",
    "            contour_stack_array = np.expand_dims(contour_array_feature, axis = 2)\n",
    "            stack_array = np.concatenate((stack_array, contour_stack_array), axis = 2)\n",
    "            \n",
    "        if edge_enhance_filter:\n",
    "            image_EDGE_ENHANCE = image.filter(ImageFilter.EDGE_ENHANCE)\n",
    "            edge_enhance_array_feature = np.array(image_EDGE_ENHANCE)\n",
    "            edge_enhance_stack_array = np.expand_dims(edge_enhance_array_feature, axis = 2)\n",
    "            stack_array = np.concatenate((stack_array, edge_enhance_stack_array), axis = 2)\n",
    "    \n",
    "        filteradded_array_feature.append(stack_array)\n",
    "    \n",
    "    filteradded_array_feature = np.array(filteradded_array_feature)\n",
    "    return filteradded_array_feature\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f06f49c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400, 8, 8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_feature_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac2a6ad3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "image has wrong mode",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_32544/2391907628.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# final_feature_train = copy.deepcopy(array_feature_train)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m final_feature_train = filter_concat(array_feature_train, blur_filter = blur_filter, contour_filter = contour_filter, \n\u001b[0m\u001b[0;32m      3\u001b[0m                   edge_enhance_filter = edge_enhance_filter)\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"최종 훈련 feature의 shape:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal_feature_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_32544/1218412440.py\u001b[0m in \u001b[0;36mfilter_concat\u001b[1;34m(array_feature, blur_filter, contour_filter, edge_enhance_filter)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mblur_filter\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m             \u001b[0mimage_BLUR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mImageFilter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBLUR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m             \u001b[0mblur_array_feature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_BLUR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mblur_stack_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblur_array_feature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mfilter\u001b[1;34m(self, filter)\u001b[0m\n\u001b[0;32m   1245\u001b[0m         \u001b[0mmultiband\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mImageFilter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMultibandFilter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1246\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbands\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mmultiband\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1247\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1249\u001b[0m         \u001b[0mims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\PIL\\ImageFilter.py\u001b[0m in \u001b[0;36mfilter\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"P\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cannot filter palette images\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilterargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: image has wrong mode"
     ]
    }
   ],
   "source": [
    "# final_feature_train = copy.deepcopy(array_feature_train)\n",
    "final_feature_train = filter_concat(array_feature_train, blur_filter = blur_filter, contour_filter = contour_filter, \n",
    "                  edge_enhance_filter = edge_enhance_filter)\n",
    "\n",
    "print(\"최종 훈련 feature의 shape:\", final_feature_train.shape)\n",
    "\n",
    "# final_feature_test = copy.deepcopy(array_feature_test)\n",
    "final_feature_test = filter_concat(array_feature_test, blur_filter = blur_filter, contour_filter = contour_filter, \n",
    "                  edge_enhance_filter = edge_enhance_filter)\n",
    "\n",
    "print(\"최종 테스트 feature의 shape:\", final_feature_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a0d4d5",
   "metadata": {},
   "source": [
    "## (3) 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222a59dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Train data 초반 70%, Test data 다음 15%, Validation data 마지막 15%\n",
    "# local_X_train = final_feature[:int(len(feature)*(1-test_size-val_size))]\n",
    "# # print(\"1st\",local_X_train.shape)\n",
    "# local_X_test = final_feature[int(len(feature)*(1-test_size-val_size)):int(len(feature)*(1-val_size))]\n",
    "# # print(\"1st\",local_X_test.shape)\n",
    "# local_X_val = final_feature[int(len(feature)*(1-val_size)):]\n",
    "# # print(\"1st\",local_X_val.shape)\n",
    "\n",
    "y_train = label_train\n",
    "y_test =  label_test\n",
    "# y_val = label[int(len(feature)*(1-val_size)):]\n",
    "\n",
    "# local_X_train, local_X_test, y_train, y_test = train_test_split(final_feature, label, \n",
    "#                                                     test_size = tts_test_size, random_state= train_test_split_randomstate)    ## test_size를 변경하며 시험.\n",
    "# Normalization\n",
    "local_X_train = final_feature_train / 255.0\n",
    "local_X_test = final_feature_test / 255.0\n",
    "# local_X_val = local_X_val / 255.0\n",
    "\n",
    "# local_X_train = final_feature_train/127.5-1\n",
    "# local_X_test = final_feature_test/127.5-1\n",
    "# BATCH_SIZE = 64\n",
    "# SHUFFLE_BUFFER_SIZE = 100\n",
    "\n",
    "# train_dataset = tf.data.Dataset.from_tensor_slices((local_X_train, y_train))\n",
    "# test_dataset = tf.data.Dataset.from_tensor_slices((local_X_test, y_test))\n",
    "# print(local_X_train.shape)\n",
    "# print(local_X_test.shape)\n",
    "# print(local_X_val.shape)\n",
    "# print(y_train.shape)\n",
    "# print(y_test.shape)\n",
    "# print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f52bddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_X_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424019da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global feature는 아직 미사용.\n",
    "# global_X_train = feature_train[:int(len(feature)*(1-test_size))]\n",
    "# global_X_test = feature_test[int(len(feature)*(1-test_size-val_size)):int(len(feature)*(1-val_size))]\n",
    "# global_X_val = feature[int(len(feature)*(1-val_size)):]\n",
    "# global_X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f56b5f",
   "metadata": {},
   "source": [
    "# 3. 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248ea8a4",
   "metadata": {},
   "source": [
    "## (1) 모델 설계 및 대표 벡터 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e2a1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e67ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat_VGG16\n",
    "\n",
    "# 1st block\n",
    "local_input = Input(shape = (upsized_image_size, upsized_image_size, filter_num+1), name = 'Local feature (Image) Input')\n",
    "x = Conv2D(64, (3,3), activation = 'sigmoid', padding = 'same', name = 'block1_conv1')(local_input)\n",
    "x = Conv2D(64, (3,3), activation = 'sigmoid', padding = 'same', name = 'block1_conv2')(x)\n",
    "x = MaxPool2D((2,2), strides = (2,2), name = 'block1_pool')(x)\n",
    "\n",
    "# 2nd block\n",
    "x = Conv2D(128, (3,3), activation = 'relu', padding = 'same', name = 'block2_conv1')(x)\n",
    "x = Conv2D(128, (3,3), activation = 'relu', padding = 'same', name = 'block2_conv2')(x)\n",
    "x = MaxPool2D((2,2), strides = (2,2), name = 'block2_pool')(x)\n",
    "\n",
    "# 3rd block\n",
    "x = Conv2D(256, (3,3), activation = 'relu', padding = 'same', name = 'block3_conv1')(x)\n",
    "x = Conv2D(256, (3,3), activation = 'relu', padding = 'same', name = 'block3_conv2')(x)\n",
    "x = Conv2D(256, (3,3), activation = 'relu', padding = 'same', name = 'block3_conv3')(x)\n",
    "x = MaxPool2D((2,2), strides = (2,2), name = 'block3_pool')(x)\n",
    "\n",
    "if upsize_factor == 1:\n",
    "    # 4th block\n",
    "    x = Conv2D(512, (3,3), activation = 'relu', padding = 'same', name = 'block4_conv1')(x)\n",
    "    x = Conv2D(512, (3,3), activation = 'relu', padding = 'same', name = 'block4_conv2')(x)\n",
    "    x = Conv2D(512, (3,3), activation = 'relu', padding = 'same', name = 'block4_conv3')(x)\n",
    "    x = MaxPool2D((2,2), strides = (2,2), name = 'block4_pool')(x)\n",
    "    \n",
    "    # 5th block\n",
    "    x = Conv2D(512, (3,3), activation = 'relu', padding = 'same', name = 'block5_conv1')(x)\n",
    "    x = Conv2D(512, (3,3), activation = 'relu', padding = 'same', name = 'block5_conv2')(x)\n",
    "    x = Conv2D(512, (3,3), activation = 'relu', padding = 'same', name = 'block5_conv3')(x)\n",
    "    x = MaxPool2D((2,2), strides = (2,2), name = 'block5_pool')(x)\n",
    "\n",
    "# Local feature + Global feature 사용\n",
    "if is_global_feature: \n",
    "    # Concatenation block\n",
    "    x = Flatten(name = 'flatten')(x)\n",
    "    global_input = Input(shape = (len(global_X_train.columns)), name = 'Global feature Input')\n",
    "    concat = concatenate([x, global_input], name = 'Feature_concatenation')\n",
    "    \n",
    "    # Final block\n",
    "    x = Dense(1024, activation = 'relu', name = 'fc1')(concat)  # 초기값 4096\n",
    "    output = Dense(1024, activation = 'relu', name = 'fc2')(x)  # 초기값 4096\n",
    "    \n",
    "    prediction = Dense(classes_num, activation = 'softmax', name = 'prediction')(output)\n",
    "    modified_VGG16_model = Model(inputs = [local_input, global_input], outputs = prediction, name = 'Concat_VGG16_model')\n",
    "\n",
    "\n",
    "# Local feature만 사용.\n",
    "else:\n",
    "    # Simpple flatten block\n",
    "    x = Flatten(name = 'flatten')(x)\n",
    "    \n",
    "    # Final block\n",
    "    x = Dense(1024, activation = 'relu', name = 'fc1')(x)       # 초기값 4096\n",
    "    output = Dense(1024, activation = 'relu', name = 'fc2')(x)  # 초기값 4096\n",
    "    \n",
    "    prediction = Dense(classes_num, activation = 'softmax', name = 'prediction')(output)    \n",
    "    modified_VGG16_model = Model(inputs = local_input, outputs = prediction, name = 'Simpler_VGG16_model')\n",
    "\n",
    "\n",
    "modified_VGG16_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d6a23c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 모델 도면 출력\n",
    "plot_model(modified_VGG16_model, 'modified_VGG16_model.png', show_shapes = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e888eeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(local_X_train.shape)\n",
    "print(local_X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dd4865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습\n",
    "modified_VGG16_model.compile(optimizer = 'adam',\n",
    "             loss = 'sparse_categorical_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "if is_global_feature:\n",
    "    modified_VGG16_model.fit([local_X_train, global_X_train], y_train, epochs = epoch_num)\n",
    "    modified_VGG16_model.evaluate([local_X_test, global_X_test], y_test, verbose = 2)\n",
    "else:\n",
    "    modified_VGG16_model.fit(local_X_train, y_train, epochs = epoch_num)\n",
    "    modified_VGG16_model.evaluate(local_X_test, y_test, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdcd864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델의 Feature list 확인\n",
    "modified_VGG16_features_list = [layer.output for layer in modified_VGG16_model.layers]\n",
    "modified_VGG16_features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8ccfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_VGG16_feat_extraction_model = Model(inputs = modified_VGG16_model.input, outputs = modified_VGG16_features_list)\n",
    "\n",
    "if is_global_feature == True:\n",
    "    train_modified_VGG16_extracted_features = modified_VGG16_feat_extraction_model([local_X_train, global_X_train])\n",
    "    test_modified_VGG16_extracted_features = modified_VGG16_feat_extraction_model([local_X_test, global_X_test])\n",
    "#     val_modified_VGG16_extracted_features = modified_VGG16_feat_extraction_model([local_X_val, global_X_val])\n",
    "else: \n",
    "    train_modified_VGG16_extracted_features = modified_VGG16_feat_extraction_model(local_X_train)\n",
    "    test_modified_VGG16_extracted_features = modified_VGG16_feat_extraction_model(local_X_test)\n",
    "#     val_modified_VGG16_extracted_features = modified_VGG16_feat_extraction_model(local_X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d61167a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_modified_VGG16_representations = np.array(train_modified_VGG16_extracted_features[0], dtype = object)\n",
    "test_modified_VGG16_representations = np.array(test_modified_VGG16_extracted_features[0], dtype = object)\n",
    "# val_modified_VGG16_representations = np.array(val_modified_VGG16_extracted_features[-2], dtype = object)\n",
    "print(type(train_modified_VGG16_representations))\n",
    "print(train_modified_VGG16_representations.shape)\n",
    "train_modified_VGG16_representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12842580",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_modified_VGG16_representations = np.array(train_modified_VGG16_extracted_features[1], dtype = object)\n",
    "print(type(dummy_modified_VGG16_representations))\n",
    "print(dummy_modified_VGG16_representations.shape)\n",
    "dummy_modified_VGG16_representations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d89951",
   "metadata": {},
   "source": [
    "## (2) 분류 예측 및 예외 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd48f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Neighbors \n",
    "KN_classifier = KNeighborsClassifier(n_neighbors = 3, p=2, metric = 'minkowski')\n",
    "KN_classifier.fit(train_modified_VGG16_representations, y_train)\n",
    "\n",
    "# Decision tree\n",
    "DT_classifier = DecisionTreeClassifier(random_state = classifier_random_state)   ## 모델 지정\n",
    "DT_classifier.fit(train_modified_VGG16_representations, y_train)\n",
    "\n",
    "\n",
    "# Random forest\n",
    "RF_classifier = RandomForestClassifier(random_state = classifier_random_state)   ## 모델 지정\n",
    "RF_classifier.fit(train_modified_VGG16_representations, y_train)\n",
    "\n",
    "\n",
    "# Support vector machine\n",
    "SVM_classifier = svm.SVC(random_state = classifier_random_state, kernel = 'linear', C = 10)   ## C가 클수록 정확해짐\n",
    "SVM_classifier.fit(train_modified_VGG16_representations, y_train)\n",
    "\n",
    "\n",
    "# Stochastic gradient descent\n",
    "SGD_classifier = SGDClassifier(random_state = classifier_random_state)   ## 모델 지정\n",
    "SGD_classifier.fit(train_modified_VGG16_representations, y_train)\n",
    "\n",
    "\n",
    "# Logistic regression\n",
    "LR_classifier = LogisticRegression(random_state = classifier_random_state, max_iter = 5000)   ## 모델 지정\n",
    "LR_classifier.fit(train_modified_VGG16_representations, y_train)\n",
    "\n",
    "# Multinomial Naive Bayes\n",
    "MNB_classifier = MultinomialNB()   ## 모델 지정\n",
    "MNB_classifier.fit(train_modified_VGG16_representations, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed17b1dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('*** K-Neighbors classifier result ***')\n",
    "KN_y_pred = KN_classifier.predict(val_modified_VGG16_representations)\n",
    "KN_report = classification_report(y_test, KN_y_pred)\n",
    "print(KN_report)\n",
    "\n",
    "print('*** Decision tree classifier result ***')\n",
    "DT_y_pred = DT_classifier.predict(val_modified_VGG16_representations)\n",
    "DT_report = classification_report(y_test, DT_y_pred)\n",
    "print(DT_report)\n",
    "\n",
    "print('*** Random forest classifier result ***')\n",
    "RF_y_pred = RF_classifier.predict(val_modified_VGG16_representations)\n",
    "RF_report = classification_report(y_test, RF_y_pred)\n",
    "print(RF_report)\n",
    "\n",
    "print('*** Support vector machine classifier result ***')\n",
    "SVM_y_pred = SVM_classifier.predict(val_modified_VGG16_representations)\n",
    "SVM_report = classification_report(y_test, SVM_y_pred)\n",
    "print(SVM_report)\n",
    "\n",
    "print('*** Stochastic gradient descent classifier result ***')\n",
    "SGD_y_pred = SGD_classifier.predict(val_modified_VGG16_representations)\n",
    "SGD_report = classification_report(y_test, SGD_y_pred)\n",
    "print(SGD_report)\n",
    "\n",
    "print('*** Logistic regression classifier result ***')\n",
    "LR_y_pred = LR_classifier.predict(val_modified_VGG16_representations)\n",
    "LR_report = classification_report(y_test, LR_y_pred)\n",
    "print(LR_report)\n",
    "\n",
    "print('*** Multinomial Naive Bayes classifier result ***')\n",
    "MNB_y_pred = MNB_classifier.predict(val_modified_VGG16_representations)\n",
    "MNB_report = classification_report(y_test, LR_y_pred)\n",
    "print(MNB_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80adba2f",
   "metadata": {},
   "source": [
    "## (3) 결과 시각화\n",
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770a5863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix 계산 및 히트맵 시각화\n",
    "\n",
    "KN_cm = confusion_matrix(y_test, KN_y_pred)\n",
    "DT_cm = confusion_matrix(y_test, DT_y_pred)\n",
    "RF_cm = confusion_matrix(y_test, RF_y_pred)\n",
    "SVM_cm = confusion_matrix(y_test, SVM_y_pred)\n",
    "SGD_cm = confusion_matrix(y_test, SGD_y_pred)\n",
    "LR_cm = confusion_matrix(y_test, LR_y_pred)\n",
    "MNB_cm = confusion_matrix(y_test, MNB_y_pred)\n",
    "\n",
    "\n",
    "\n",
    "sns.set(rc = {'figure.figsize':(15,15)})\n",
    "fig, axes = plt.subplots(nrows = 4, ncols = 2)\n",
    "sns.heatmap(KN_cm/np.sum(KN_cm), annot=True, fmt='.2%', cmap='Blues', ax = axes[0,0])\n",
    "sns.heatmap(DT_cm/np.sum(DT_cm), annot=True, fmt='.2%', cmap='Blues', ax = axes[0,1])\n",
    "sns.heatmap(RF_cm/np.sum(RF_cm), annot=True, fmt='.2%', cmap='Blues', ax = axes[1,0])\n",
    "sns.heatmap(SVM_cm/np.sum(SVM_cm), annot=True, fmt='.2%', cmap='Blues', ax = axes[1,1])\n",
    "sns.heatmap(SGD_cm/np.sum(SGD_cm), annot=True, fmt='.2%', cmap='Blues', ax = axes[2,0])\n",
    "sns.heatmap(LR_cm/np.sum(LR_cm), annot=True, fmt='.2%', cmap='Blues', ax = axes[2,1])\n",
    "sns.heatmap(MNB_cm/np.sum(MNB_cm), annot=True, fmt='.2%', cmap='Blues', ax = axes[3,0])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97657c1a",
   "metadata": {},
   "source": [
    "### TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8f5e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# representation 벡터 형태 변환\n",
    "train_df = pd.DataFrame(train_modified_VGG16_representations)\n",
    "\n",
    "# 2차원 t-SNE 임베딩\n",
    "tsne_np = TSNE(n_components = 2).fit_transform(train_df)\n",
    "\n",
    "# numpy array -> DataFrame 변환\n",
    "tsne_df = pd.DataFrame(tsne_np, columns = ['component 0', 'component 1'])\n",
    "\n",
    "df_y = np.array(y_train)\n",
    "df_y = pd.DataFrame(df_y)\n",
    "tsne_df['target'] = pd.DataFrame(df_y)\n",
    "\n",
    "# target 별 분리\n",
    "tsne_df_0 = tsne_df[tsne_df['target'] == 0]\n",
    "tsne_df_1 = tsne_df[tsne_df['target'] == 1]\n",
    "tsne_df_2 = tsne_df[tsne_df['target'] == 2]\n",
    "tsne_df_3 = tsne_df[tsne_df['target'] == 3]\n",
    "tsne_df_4 = tsne_df[tsne_df['target'] == 4]\n",
    "tsne_df_5 = tsne_df[tsne_df['target'] == 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e0ba09",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(tsne_df_0['component 0'], tsne_df_0['component 1'], color = 'pink', label = 'SDW')\n",
    "plt.scatter(tsne_df_1['component 0'], tsne_df_1['component 1'], color = 'purple', label = 'PSH')\n",
    "plt.scatter(tsne_df_2['component 0'], tsne_df_2['component 1'], color = 'yellow', label = 'LTS')\n",
    "plt.scatter(tsne_df_3['component 0'], tsne_df_3['component 1'], color = 'red', label = 'CJH')\n",
    "plt.scatter(tsne_df_4['component 0'], tsne_df_4['component 1'], color = 'blue', label = 'LCY')\n",
    "plt.scatter(tsne_df_5['component 0'], tsne_df_5['component 1'], color = 'green', label = 'HHY')\n",
    "\n",
    "plt.xlabel('component 0')\n",
    "plt.ylabel('component 1')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('tsne_sample.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6e9516",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metric_learn import LMNN\n",
    "from metric_learn import NCA\n",
    "from metric_learn import LFDA\n",
    "from metric_learn import MLKR\n",
    "from metric_learn import MMC_Supervised\n",
    "\n",
    "\n",
    "lmnn = LMNN(k=5, learn_rate=1e-6)\n",
    "lmnn.fit(train_modified_VGG16_representations, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19b3d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "nca = NCA(max_iter=1000)\n",
    "nca.fit(train_modified_VGG16_representations, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b04e320",
   "metadata": {},
   "outputs": [],
   "source": [
    "lfda = LFDA(k=2)\n",
    "lfda.fit(train_modified_VGG16_representations, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc32a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlkr = MLKR()\n",
    "mlkr.fit(train_modified_VGG16_representations, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8f2bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmc = MMC_Supervised(num_constraints=200)\n",
    "mmc.fit(train_modified_VGG16_representations, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
